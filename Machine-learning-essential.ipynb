{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukunzeabby/Cluster-Analysis-on-the-climate-variables-over-Darsalam-city/blob/main/Machine-learning-essential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ7XhhkbW4Y6"
      },
      "source": [
        "# Hands-on tutorial: Machine Learning - basics\n",
        "**Author:** Dr. Habiboulaye {@gmail.com}\n",
        "\n",
        "This hand-on tutorial will conver:\n",
        "\n",
        "* Linear Regression\n",
        "* Polynomial Regression\n",
        "* Ridge Regression\n",
        "(This notebook is inspired by the work of Animesh Agarwal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15YnU7BUW4Y7"
      },
      "source": [
        "## Populating the namespace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-28T09:10:51.520376Z",
          "start_time": "2020-01-28T09:10:48.277734Z"
        },
        "scrolled": true,
        "id": "-dkgwIcfW4Y7"
      },
      "source": [
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "colors = ['seagreen','blue', 'darkorange', 'indigo', 'yellow', 'purple', 'violet', 'turquoise']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TDV9_0yW4Y7"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-28T09:25:47.099482Z",
          "start_time": "2020-01-28T09:25:46.913353Z"
        },
        "scrolled": true,
        "id": "UDta79GrW4Y8"
      },
      "source": [
        "#@title\n",
        "#Generate data\n",
        "np.random.seed(0)\n",
        "N = 20\n",
        "x_orig = 2 - 3 * np.random.normal(0, 1, N)\n",
        "y_orig = x_orig - 2 * (x_orig ** 2) + 0.5 * (x_orig ** 3) + np.random.normal(-5, 5, N) \n",
        "\n",
        "# transforming the data to include another axis\n",
        "x = x_orig[:, np.newaxis]\n",
        "y = y_orig[:, np.newaxis]\n",
        "plt.scatter(x,y, s=30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDregMH735vO"
      },
      "source": [
        "<font color='red'>\n",
        "<b>EXERCICES</b>: Replace the <b>FILL_IN</b> pattern with the correct codes then execute the cell\n",
        " </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAxBQF9aW4Y9"
      },
      "source": [
        "## Linear Regression  \n",
        "\n",
        "* Take a look at the scikit-learn user guide for more details on [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-28T09:17:13.596266Z",
          "start_time": "2020-01-28T09:17:11.644564Z"
        },
        "scrolled": true,
        "id": "zRLL_DiYW4Y9"
      },
      "source": [
        "# Import the linear regression model from scikit-learn \n",
        "from sklearn.linear_model import <FILL_IN>\n",
        "# Import the mean_squared_error metric\n",
        "from sklearn.metrics import <FILL_IN>\n",
        "# Instanciate a linear model using the class LinearRegression with default parameters\n",
        "model = <FILL_IN> \n",
        "# Use the method fit to train the model with input data x and output y\n",
        "<FILL_IN> \n",
        "# Use the trained model to predict output y_pred from input x\n",
        "y_pred = <FILL_IN> \n",
        "# Performance metrics\n",
        "rmse = np.sqrt(<FILL_IN>(y,y_pred))\n",
        "print('rmse:',rmse)\n",
        "\n",
        "# plot the model\n",
        "plt.scatter(x, y, s=40)\n",
        "plt.title('Linear Regression')\n",
        "plt.plot(x, y_pred, color=colors[0],label='lineareg')\n",
        "#plt.scatter(x, y_pred, s=20)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "# Performance metrics\n",
        "rmse = np.sqrt(<FILL_IN>(y,y_pred))\n",
        "r2 = r2_score(y,y_pred)\n",
        "print('rmse:',rmse)\n",
        "print('r2  :', r2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHqgmpbaW4Y-"
      },
      "source": [
        "<font color='red'>\n",
        "    \n",
        "**Conclusion**: ??\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsMvHSNGW4Y-"
      },
      "source": [
        "## Polynomial Regression: linear model with polynomial features\n",
        "\n",
        "To overcome under-fitting, we need to **increase the complexity of the model**.  \n",
        "**Idea**: convert the original features into their higher order terms we will use the [**PolynomialFeatures**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) class provided by **scikit-learn**. Next, we train the model using Linear Regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-28T10:18:21.117873Z",
          "start_time": "2020-01-28T10:18:20.645819Z"
        },
        "scrolled": true,
        "id": "1957puNdW4Y_"
      },
      "source": [
        "import operator\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Import the package polynomial features generation package\n",
        "from sklearn.preprocessing import <FILL_IN>\n",
        "\n",
        "\n",
        "# Instanciate a new Linear Regression model\n",
        "model = LinearRegression()\n",
        "plt.figure(figsize=(15,4))\n",
        "# Create Polynomial features with degree 1, then 4 then, 10 (from original input x => (x^0, x^1, ...x^degree) \n",
        "for i,degree in enumerate([1,4,10]):\n",
        "    # transforming the data to include another axis\n",
        "    x = x_orig[:, np.newaxis]\n",
        "    y = y_orig[:, np.newaxis]\n",
        "    print('instance:{}: poly_degree: {}'.format(i,degree))\n",
        "    # Create an instance of class PolynomialFeatures\n",
        "    polynomial_features = <FILL_IN>\n",
        "    # Use fit_transform method of class PolynomialFeatures to create new features vector x_poly\n",
        "    x_poly = <FILL_IN>\n",
        "    # Train the model using the polynomial features vector x_poly and output y\n",
        "    <FILL_IN>\n",
        "    # Use the trained model to predict output from vector x_poly\n",
        "    y_poly_pred = <FILL_IN>\n",
        "    # Performance\n",
        "    rmse = np.sqrt(<FILL_IN>(y,y_poly_pred))\n",
        "    r2 = r2_score(y,y_poly_pred)\n",
        "    print('rmse',rmse)\n",
        "    print(r2)\n",
        "    # plot\n",
        "    plt.subplot(1,3,1+i)\n",
        "    plt.scatter(x, y, s=40)\n",
        "    # sort the values of x before line plot\n",
        "    sort_axis = operator.itemgetter(0)\n",
        "    sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
        "    x, y_poly_pred = zip(*sorted_zip)\n",
        "    plt.plot(x, y_poly_pred, color=colors[i], label='degree='+str(degree))\n",
        "    plt.title('Polynomial Regression')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print('poly_features')\n",
        "print('without poly_features:', x[0])\n",
        "print('adding  poly_features:', x_poly[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdTsTypzhxC"
      },
      "source": [
        "**Conclusion**: ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw2E4-XOW4ZA"
      },
      "source": [
        "## Ridge Regression: Overffiting and Regularization\n",
        "* Take a look at the scikit-learn user guide for more details on [RidgeRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) api  \n",
        "λ (i.e penalty_lambda) is the tuning parameter that decides how much we want to penalize the flexibility of our model.   \n",
        " - When λ = 0, the penalty term has no eﬀect, and the estimates produced by ridge regression will be equal to least squares.   \n",
        " - However, as λ→∞, the impact of the shrinkage penalty grows, and the ridge regression coeﬃcient estimates will approach zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-01-28T10:24:38.834161Z",
          "start_time": "2020-01-28T10:24:38.272229Z"
        },
        "scrolled": true,
        "id": "H9g46hiRW4ZA"
      },
      "source": [
        "\n",
        "# Import the Ridge regressor from sklearn linear model\n",
        "from sklearn.linear_model import <FILL_IN>\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "\n",
        "# Loop for varying the penalty_lambda to see the regulation impact on overfitting (of previous model)\n",
        "for i,penalty_lambda in enumerate([0.,10.,1000]):\n",
        "    # transforming the data to include another axis\n",
        "    x = x_orig[:, np.newaxis]\n",
        "    y = y_orig[:, np.newaxis]\n",
        "    print('instance:{}: poly_degree: {}'.format(i,10))\n",
        "    polynomial_features= PolynomialFeatures(degree=degree)\n",
        "    x_poly = polynomial_features.fit_transform(x)\n",
        "    # Create an instance of Rigde Regression model with parameter alpha = penalty_lambda\n",
        "    model = <FILL_IN>\n",
        "    # Train the Ridge using the polynomial features vector x_poly and output y\n",
        "    <FILL_IN>\n",
        "    # Use the trained model to predict output from vector x_poly\n",
        "    y_poly_pred = <FILL_IN>\n",
        "    # Performance\n",
        "    rmse = np.sqrt(<FILL_IN>(y,y_poly_pred))\n",
        "    r2 = r2_score(y,y_poly_pred)\n",
        "    print('rmse',rmse)\n",
        "    print(r2)\n",
        "    # plot\n",
        "    plt.subplot(1,3,1+i)\n",
        "    plt.scatter(x, y, s=40)\n",
        "    # sort the values of x before line plot\n",
        "    sort_axis = operator.itemgetter(0)\n",
        "    sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
        "    x, y_poly_pred = zip(*sorted_zip)\n",
        "    plt.plot(x, y_poly_pred, color=colors[i], label='lambda='+str(penalty_lambda))\n",
        "    plt.title('Ridge Regression')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqOKdhqUzgEw"
      },
      "source": [
        "**Conclusion**: ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnH9Su22KCz"
      },
      "source": [
        "## Lasso Regression: Conduct your own experiments (bonus)\n",
        "* Find Lasso model api on [scikit-learn documentation](https://scikit-learn.org/stable/) and take a look for more details \n",
        "\n",
        "* For any question: Keep in mind that [*ChatGPT*](https://chat.openai.com/) and [*Google*](https://www.google.com/) are your friends."
      ]
    }
  ]
}